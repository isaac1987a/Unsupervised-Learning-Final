{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e3e17d-dca0-47fb-bb08-b937506f2ec7",
   "metadata": {},
   "source": [
    "# Hate Speach Detection\n",
    "I want to build an algorithim to detect hate speach.  This will use the Hate Speach and Offensive Language dataset at https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset?select=labeled_data.csv.  This dataset is 24782 tweets long with users voting on if the tweet is offensive, hate_speach or neither, with the winning label being selected as a class.\n",
    "### Disclaimer\n",
    "This assignment necissarly contains hate speach, and offensive langauge.  This does not represent the views of the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c222a22a-d816-4d91-b317-0908f884f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7927248-8812-484d-97e0-e26c4530a697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0               0      3            0                   0        3      2   \n",
      "1               1      3            0                   3        0      1   \n",
      "2               2      3            0                   3        0      1   \n",
      "3               3      3            0                   2        1      1   \n",
      "4               4      6            0                   6        0      1   \n",
      "...           ...    ...          ...                 ...      ...    ...   \n",
      "24778       25291      3            0                   2        1      1   \n",
      "24779       25292      3            0                   1        2      2   \n",
      "24780       25294      3            0                   3        0      1   \n",
      "24781       25295      6            0                   6        0      1   \n",
      "24782       25296      3            0                   0        3      2   \n",
      "\n",
      "                                                   tweet  \n",
      "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
      "...                                                  ...  \n",
      "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
      "24779  you've gone and broke the wrong heart baby, an...  \n",
      "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
      "24781              youu got wild bitches tellin you lies  \n",
      "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
      "\n",
      "[24783 rows x 7 columns]\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#Initial Import\n",
    "raw_data = pd.read_csv(\"https://raw.githubusercontent.com/isaac1987a/Unsupervised-Learning-Final/main/Data/labeled_data.csv?token=GHSAT0AAAAAACF7NRVLC2IG24UXMHK4V7IGZGP3FLQ\", header = 0)\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0eebb-45e3-4012-9973-88a5b302d2b1",
   "metadata": {},
   "source": [
    "## Import and Cleaning\n",
    "### Import\n",
    "This data imports fairly easily.  I donloaded a copy of the file from kaggle and mirrored it to my GitHub so I could autodownload it for your use.\n",
    "### Cleaning\n",
    "#### **Tweets with newline**\n",
    "There appears to be a mismatch between the number of lines generated and the number of lines imported.  This is caused by newline characters, commas, quotation marks, and other supidity mixed in.\n",
    "\n",
    "##### **Some examples of bad formating.**\n",
    "22422,3,0,3,0,1,\"This bitch fell straight through the chair... Im high, of course I laughed..\\\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "Even if I wasn't I would've still laughed.\"\n",
    "\n",
    "256,3,0,3,0,1,\"\"\"@TheNewSAT: #NewSATQuestions\\\n",
    "Yeah bitch, yeah bitch, call me _______:\\\n",
    "a.) Maybe\\\n",
    "b.) Steve-O\\\n",
    "c.) Later\\\n",
    "d.) Jesse Pinkman\"\"\\\n",
    "@machinegunkelly\"\n",
    "\n",
    "##### **Fix Action** \n",
    "The fix action is to build my own reader to import the data.  \n",
    "\n",
    "#### **Username Cleanup**\n",
    "I chose to just drop all usernames.  This simplified\n",
    "#### **Unicode Characters and non-text characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5093c7e-fbd8-468e-ab66-ed5ff5cfb432",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/labeled_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns \u001b[38;5;241m=\u001b[39m col_names)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Open File\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m file1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/labeled_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m Lines \u001b[38;5;241m=\u001b[39m file1\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m      6\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/labeled_data.csv'"
     ]
    }
   ],
   "source": [
    "col_names = [\"tweet Num\", \"count\", \"hate_speech\", \"offensive_language\", \"neither\", \"class\",\"tweet text\"]\n",
    "raw_data = pd.DataFrame(columns = col_names)\n",
    "#Open File\n",
    "file1 = open('data/labeled_data.csv', 'r')\n",
    "Lines = file1.readlines()\n",
    "i = 0\n",
    "for line in Lines:\n",
    "    #If line is good\n",
    "    if re.search(\"[0-9]{1,5},([0-9],){5}\", line) != None:\n",
    "        #Extract the leading values\n",
    "        values = re.findall(\"[0-9]{1,5},([0-9],){5}\", line)\n",
    "        #extract the text\n",
    "        text = re.split(\"[0-9]{1,5},([0-9],){5}\", line)\n",
    "        #extract the indevedual values into a thingy\n",
    "        values = re.split(\",\", values)\n",
    "        values.append(text)\n",
    "        newline = pd.DataFrame(values, columns = col_names)\n",
    "        pd.concat(raw_data, newline)\n",
    "        i += 1\n",
    "        if i > 20:\n",
    "            print(raw_data)\n",
    "            break\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b83e21c-87b7-4108-a875-e520d58d13c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
